---
MXNET_VERSION: "mxnet"
output_path: "./output/rcnn/DOTA_quadrangle"
symbol: resnet_v1_101_rcnn_quadrangle
gpus: '0'
CLASS_AGNOSTIC: false
RESIZE_TO_FIX_SIZE: true
# if RESIZE_TO_FIX_SIZE is true, the SCALES means target size of width and height
SCALES:
- 1024
- 1024
default:
  frequent: 100
  kvstore: device
network:
  pretrained: "./model/pretrained_model/resnet_v1_101"
  pretrained_epoch: 0
  PIXEL_MEANS:
  - 103.06
  - 115.90
  - 123.15
  IMAGE_STRIDE: 0
  RCNN_FEAT_STRIDE: 16
  RPN_FEAT_STRIDE: 16
  FIXED_PARAMS:
  - conv1
  - bn_conv1
  - res2
  - bn2
  - gamma
  - beta
  FIXED_PARAMS_SHARED:
  - conv1
  - bn_conv1
  - res2
  - bn2
  - res3
  - bn3
  - res4
  - bn4
  - gamma
  - beta
  ANCHOR_RATIOS:
  - 0.5
  - 1
  - 2
  ANCHOR_SCALES:
  - 8
  - 16
  - 32
  NUM_ANCHORS: 9
dataset:
  NUM_CLASSES: 16
  dataset: DOTA_oriented
#  dataset_path: "/data/dj/dota/dota-split"
  dataset_path: "/data/dj/ODAI/ODAI_test_split"
  image_set: train
#  root_path: "/home/dj/data/"
  root_path: "/data/dj/ODAI"
  test_image_set: test
  proposal: rpn
TRAIN:
  lr: 0.0005
  lr_step: '45,52'
  lr_factor: 0.1
  warmup: true
  warmup_lr: 0.00005
  # typically we will use 1000 warmup step for single GPU on DOTA
  warmup_step: 1000
  begin_epoch: 0
  end_epoch: 60
  model_prefix: 'rcnn_DOTA_quadrangle'
  # whether resume training
  RESUME: false
  # whether flip image, as for quadrangle image, we have to carefully decide whether to flip it
  FLIP: true
  # whether shuffle image
  SHUFFLE: true
  # whether use OHEM
  ENABLE_OHEM: true
  # size of images for each device, 2 for rcnn, 1 for rpn and e2e
  BATCH_IMAGES: 1
  # e2e changes behavior of anchor loader and metric
  END2END: true
  # group images with similar aspect ratio
  ASPECT_GROUPING: true
  # R-CNN
  # rcnn rois batch size
  BATCH_ROIS: 128
  BATCH_ROIS_OHEM: 128
  # rcnn rois sampling params
  FG_FRACTION: 0.25
  FG_THRESH: 0.5
  BG_THRESH_HI: 0.5
  BG_THRESH_LO: 0.1
  # rcnn bounding box regression params
  BBOX_REGRESSION_THRESH: 0.5
  BBOX_WEIGHTS:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0

  # RPN anchor loader
  # rpn anchors batch size
  RPN_BATCH_SIZE: 256
  # rpn anchors sampling params
  RPN_FG_FRACTION: 0.5
  RPN_POSITIVE_OVERLAP: 0.7
  RPN_NEGATIVE_OVERLAP: 0.3
  RPN_CLOBBER_POSITIVES: false
  # rpn bounding box regression params
  RPN_BBOX_WEIGHTS:
  - 1.0
  - 1.0
  - 1.0
  - 1.0

  RPN_POSITIVE_WEIGHT: -1.0
  # used for end2end training
  # RPN proposal
  CXX_PROPOSAL: false
  RPN_NMS_THRESH: 0.7
  RPN_PRE_NMS_TOP_N: 6000
  RPN_POST_NMS_TOP_N: 300
  RPN_MIN_SIZE: 0

  # approximate bounding box regression
  BBOX_NORMALIZATION_PRECOMPUTED: false
  BBOX_MEANS:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  BBOX_STDS:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
TEST:
  # use rpn to generate proposal
  HAS_RPN: true
  # size of images for each device
  BATCH_IMAGES: 1
  # RPN proposal
  CXX_PROPOSAL: false
  RPN_NMS_THRESH: 0.7
  RPN_PRE_NMS_TOP_N: 6000
  RPN_POST_NMS_TOP_N: 300
  RPN_MIN_SIZE: 0
  # RPN generate proposal
  PROPOSAL_NMS_THRESH: 0.7
  PROPOSAL_PRE_NMS_TOP_N: 20000
  PROPOSAL_POST_NMS_TOP_N: 2000
  PROPOSAL_MIN_SIZE: 0
  # RCNN nms
  NMS: 0.3
  test_epoch: 59
  save_img_path: '/home/dj/data/vis'
